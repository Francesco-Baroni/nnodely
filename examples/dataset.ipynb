{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNodely Documentation - Load Data\n",
    "\n",
    "Listed here are all the modalitites by which you can load data inside the nnodely framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>-- nnodely_v1.3.1 --<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n"
     ]
    }
   ],
   "source": [
    "# uncomment the command below to install the nnodely package\n",
    "#!pip install nnodely\n",
    "\n",
    "from nnodely import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Dataset from files\n",
    "\n",
    "Load a dataset inside the framework using a directory. \n",
    "\n",
    "You must specify a name for the dataset, the folder path and also the structure of the data so that the framework will know which column must be used for every input of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input('in1')\n",
    "target = Input('target')\n",
    "relation = Fir(input.tw(0.05))\n",
    "output = Output('out', relation)\n",
    "\n",
    "model = Modely(visualizer=None)\n",
    "model.addMinimize('out', output, target.last())\n",
    "model.neuralizeModel(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'path/to/train/folder'\n",
    "data_struct = ['in1', '', 'target']\n",
    "model.loadData(name='dataset', source=train_folder, format=data_struct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also specify various parameters such as the number of lines to skip, the delimiter to use between data and if you want to include the header of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.loadData(name='dataset_2', source=train_folder, format=data_struct, skiplines=4, delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset from a custom dictionary\n",
    "\n",
    "you can build your own dataset with a dictionary containing all the necessary inputs of the network and passing it to the 'source' attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[loadData] Dataset named dataset_3 already loaded! overriding the existing one..\u001b[0m\n",
      "{'target': array([[[ 5]],\n",
      "\n",
      "       [[ 7]],\n",
      "\n",
      "       [[ 9]],\n",
      "\n",
      "       [[11]],\n",
      "\n",
      "       [[13]],\n",
      "\n",
      "       [[15]]]), 'in1': array([[[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]],\n",
      "\n",
      "       [[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5]],\n",
      "\n",
      "       [[2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]],\n",
      "\n",
      "       [[3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7]],\n",
      "\n",
      "       [[4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8]],\n",
      "\n",
      "       [[5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]]])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_x = np.array(range(10))\n",
    "data_a = 2\n",
    "data_b = -3\n",
    "dataset = {'in1': data_x, 'target': (data_a*data_x) + data_b}\n",
    "\n",
    "model.loadData(name='dataset_3', source=dataset)\n",
    "print(model.data['dataset_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset from a pandas DataFrame\n",
    "\n",
    "you can also use a pandas dataframe as source for loading a dataset inside the nnodely framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "NeuObj.clearNames()\n",
    "x = Input('x')\n",
    "y = Input('y')\n",
    "k = Input('k')\n",
    "w = Input('w')\n",
    "\n",
    "out = Output('out', Fir(x.tw(0.02) + y.tw(0.02)))\n",
    "out2 = Output('out2', Fir(k.last()) + Fir(w.tw(0.05,offset=-0.02)))\n",
    "\n",
    "model = Modely(visualizer=None)\n",
    "model.addMinimize('out', out, out2)\n",
    "model.neuralizeModel(0.01)\n",
    "\n",
    "# Create a DataFrame with random values for each input\n",
    "df = pd.DataFrame({\n",
    "    'x': np.linspace(1,100,100, dtype=np.float32),\n",
    "    'y': np.linspace(1,100,100, dtype=np.float32),\n",
    "    'k': np.linspace(1,100,100, dtype=np.float32),\n",
    "    'w': np.linspace(1,100,100, dtype=np.float32)})\n",
    "\n",
    "model.loadData(name='dataset_4', source=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling a pandas DataFrame\n",
    "\n",
    "if you have a column representing time (must be a datetime object) you can also use those values to resample the dataset using the sample time of the neuralized network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'time': np.array([1.0,1.5,2.0,4.0,4.5,5.0,7.0,7.5,8.0,8.5], dtype=np.float32),\n",
    "    'x': np.linspace(1,10,10, dtype=np.float32),\n",
    "    'y': np.linspace(1,10,10, dtype=np.float32),\n",
    "    'k': np.linspace(1,10,10, dtype=np.float32),\n",
    "    'w': np.linspace(1,10,10, dtype=np.float32)})\n",
    "\n",
    "model.loadData(name='dataset_resampled', source=df, resampling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Samples from the Dataset\n",
    "\n",
    "Once a dataset is loaded, you can use it to get random samples from the dataset. Set the 'window' argument to choose the number of samples to get from the specific dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'out2': [50.548545837402344, 51.15421676635742, 51.759891510009766, 52.36556625366211, 52.97123718261719], 'out': [171.63796997070312, 173.55892944335938, 175.47988891601562, 177.40086364746094, 179.3218231201172]}\n"
     ]
    }
   ],
   "source": [
    "sample = model.getSamples(dataset='dataset_4', window=5)\n",
    "result = model(sample, sampled=True)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
