{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNodely Documentation - Training\n",
    "\n",
    "Here are listed all the modalities that can be used to perform the training process of a neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>-- nnodely_v1.5.0 --<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n"
     ]
    }
   ],
   "source": [
    "# uncomment the command below to install the nnodely package\n",
    "#!pip install nnodely\n",
    "\n",
    "from nnodely import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m================================ nnodely Model =================================\u001b[0m\n",
      "\u001b[32m{'Constants': {},\n",
      " 'Functions': {},\n",
      " 'Info': {'SampleTime': 0.01,\n",
      "          'nnodely_version': '1.5.0',\n",
      "          'ns': [5, 0],\n",
      "          'ntot': 5,\n",
      "          'num_parameters': 5},\n",
      " 'Inputs': {'in1': {'dim': 1, 'ns': [5, 0], 'ntot': 5, 'tw': [-0.05, 0]},\n",
      "            'target': {'dim': 1, 'ns': [1, 0], 'ntot': 1, 'sw': [-1, 0]}},\n",
      " 'Minimizers': {'error': {'A': 'Fir2', 'B': 'SamplePart4', 'loss': 'mse'}},\n",
      " 'Models': 'model',\n",
      " 'Outputs': {'out': 'Fir2'},\n",
      " 'Parameters': {'PFir3W': {'dim': 1,\n",
      "                           'tw': 0.05,\n",
      "                           'values': [[0.11196976900100708],\n",
      "                                      [0.6354063153266907],\n",
      "                                      [0.556776762008667],\n",
      "                                      [0.5707035660743713],\n",
      "                                      [0.7967591285705566]]}},\n",
      " 'Relations': {'Fir2': ['Fir', ['TimePart1'], 'PFir3W', None, 0],\n",
      "               'SamplePart4': ['SamplePart', ['target'], -1, [-1, 0]],\n",
      "               'TimePart1': ['TimePart', ['in1'], -1, [-0.05, 0]]}}\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Model Dataset =============================\u001b[0m\n",
      "\u001b[32mDataset Name:                 dataset\u001b[0m\n",
      "\u001b[32mNumber of files:              1\u001b[0m\n",
      "\u001b[32mTotal number of samples:      27\u001b[0m\n",
      "\u001b[32mShape of in1:                 (27, 5, 1)\u001b[0m\n",
      "\u001b[32mShape of target:              (27, 1, 1)\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Create a neural network model and Load a dataset\n",
    "in1 = Input('in1')\n",
    "target = Input('target')\n",
    "relation = Fir(in1.tw(0.05))\n",
    "output = Output('out', relation)\n",
    "\n",
    "model = Modely(visualizer=TextVisualizer())\n",
    "model.addMinimize('error', output, target.last())\n",
    "model.addModel('model', output)\n",
    "model.neuralizeModel(0.01)\n",
    "\n",
    "train_folder = 'data'\n",
    "data_struct = ['in1', '', 'target']\n",
    "model.loadData(name='dataset', source=train_folder, format=data_struct, skiplines=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Parameters and Usage\n",
    "\n",
    "With the `trainModel` function the user can perform a training process by setting different parameters of training such as:\n",
    "\n",
    "- models to train\n",
    "- training and validation dataset\n",
    "- number of epochs of training\n",
    "- data shuffling\n",
    "- train and validation batch size\n",
    "- learning rate\n",
    "\n",
    "And many more advanced settings.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no parameters are specified, the function will train all the built models using all the loaded dataset with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m======================== nnodely Model Train Parameters ========================\u001b[0m\n",
      "\u001b[32mmodels:                       ['model']\u001b[0m\n",
      "\u001b[32mnum of epochs:                100\u001b[0m\n",
      "\u001b[32mupdate per epochs:            1\u001b[0m\n",
      "\u001b[34m└>(n_samples-batch_size)/batch_size+1\u001b[0m\n",
      "\u001b[32mshuffle _data:                True\u001b[0m\n",
      "\u001b[32mtrain dataset:                dataset_train\u001b[0m\n",
      "\u001b[32m\t- num of samples:            27\u001b[0m\n",
      "\u001b[32m\t- batch size:                27\u001b[0m\n",
      "\u001b[32m\t- unused samples:            0\u001b[0m\n",
      "\u001b[34m\t  └>n_samples-update_per_epochs*batch_size\u001b[0m\n",
      "\u001b[32mminimizers:                   {'error': {'A': 'Fir2',\n",
      "                                         'B': 'SamplePart4',\n",
      "                                         'loss': 'mse'}}\u001b[0m\n",
      "\u001b[32moptimizer:                    Adam\u001b[0m\n",
      "\u001b[32moptimizer defaults:           {'lr': 0.001}\u001b[0m\n",
      "\u001b[32moptimizer params:             [{'params': 'PFir3W'}]\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================= nnodely Training =================\u001b[0m\n",
      "\u001b[32m|  Epoch   |\u001b[0m\u001b[32m       error       |\u001b[0m\u001b[32m       Total       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m        Loss       |\u001b[0m\u001b[32m        Loss       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m       train       |\u001b[0m\u001b[32m       train       |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|  10/100  |\u001b[0m\u001b[32m     6.316e+02     |\u001b[0m\u001b[32m     6.316e+02     |\u001b[0m\n",
      "\u001b[32m|  20/100  |\u001b[0m\u001b[32m     5.902e+02     |\u001b[0m\u001b[32m     5.902e+02     |\u001b[0m\n",
      "\u001b[32m|  30/100  |\u001b[0m\u001b[32m     5.505e+02     |\u001b[0m\u001b[32m     5.505e+02     |\u001b[0m\n",
      "\u001b[32m|  40/100  |\u001b[0m\u001b[32m     5.128e+02     |\u001b[0m\u001b[32m     5.128e+02     |\u001b[0m\n",
      "\u001b[32m|  50/100  |\u001b[0m\u001b[32m      4.77e+02     |\u001b[0m\u001b[32m      4.77e+02     |\u001b[0m\n",
      "\u001b[32m|  60/100  |\u001b[0m\u001b[32m     4.431e+02     |\u001b[0m\u001b[32m     4.431e+02     |\u001b[0m\n",
      "\u001b[32m|  70/100  |\u001b[0m\u001b[32m     4.110e+02     |\u001b[0m\u001b[32m     4.110e+02     |\u001b[0m\n",
      "\u001b[32m|  80/100  |\u001b[0m\u001b[32m     3.808e+02     |\u001b[0m\u001b[32m     3.808e+02     |\u001b[0m\n",
      "\u001b[32m|  90/100  |\u001b[0m\u001b[32m     3.523e+02     |\u001b[0m\u001b[32m     3.523e+02     |\u001b[0m\n",
      "\u001b[32m| 100/100  |\u001b[0m\u001b[32m     3.255e+02     |\u001b[0m\u001b[32m     3.255e+02     |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Training Time =============================\u001b[0m\n",
      "\u001b[32mTotal time of Training:       0.07600164413452148\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_parameters = model.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m======================== nnodely Model Train Parameters ========================\u001b[0m\n",
      "\u001b[32mmodels:                       ['model']\u001b[0m\n",
      "\u001b[32mnum of epochs:                10\u001b[0m\n",
      "\u001b[32mupdate per epochs:            6\u001b[0m\n",
      "\u001b[34m└>(n_samples-batch_size)/batch_size+1\u001b[0m\n",
      "\u001b[32mshuffle _data:                True\u001b[0m\n",
      "\u001b[32mtrain dataset:                dataset\u001b[0m\n",
      "\u001b[32m\t- num of samples:            27\u001b[0m\n",
      "\u001b[32m\t- batch size:                4\u001b[0m\n",
      "\u001b[32m\t- unused samples:            3\u001b[0m\n",
      "\u001b[34m\t  └>n_samples-update_per_epochs*batch_size\u001b[0m\n",
      "\u001b[32mminimizers:                   {'error': {'A': 'Fir2',\n",
      "                                         'B': 'SamplePart4',\n",
      "                                         'loss': 'mse'}}\u001b[0m\n",
      "\u001b[32moptimizer:                    Adam\u001b[0m\n",
      "\u001b[32moptimizer defaults:           {'lr': 0.01}\u001b[0m\n",
      "\u001b[32moptimizer params:             [{'params': 'PFir3W'}]\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================= nnodely Training =================\u001b[0m\n",
      "\u001b[32m|  Epoch   |\u001b[0m\u001b[32m       error       |\u001b[0m\u001b[32m       Total       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m        Loss       |\u001b[0m\u001b[32m        Loss       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m       train       |\u001b[0m\u001b[32m       train       |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|   1/10   |\u001b[0m\u001b[32m     2.949e+02     |\u001b[0m\u001b[32m     2.949e+02     |\u001b[0m\n",
      "\u001b[32m|   2/10   |\u001b[0m\u001b[32m     1.457e+02     |\u001b[0m\u001b[32m     1.457e+02     |\u001b[0m\n",
      "\u001b[32m|   3/10   |\u001b[0m\u001b[32m     6.707e+01     |\u001b[0m\u001b[32m     6.707e+01     |\u001b[0m\n",
      "\u001b[32m|   4/10   |\u001b[0m\u001b[32m     2.173e+01     |\u001b[0m\u001b[32m     2.173e+01     |\u001b[0m\n",
      "\u001b[32m|   5/10   |\u001b[0m\u001b[32m     3.984e+00     |\u001b[0m\u001b[32m     3.984e+00     |\u001b[0m\n",
      "\u001b[32m|   6/10   |\u001b[0m\u001b[32m     1.901e+00     |\u001b[0m\u001b[32m     1.901e+00     |\u001b[0m\n",
      "\u001b[32m|   7/10   |\u001b[0m\u001b[32m     3.562e+00     |\u001b[0m\u001b[32m     3.562e+00     |\u001b[0m\n",
      "\u001b[32m|   8/10   |\u001b[0m\u001b[32m     4.017e+00     |\u001b[0m\u001b[32m     4.017e+00     |\u001b[0m\n",
      "\u001b[32m|   9/10   |\u001b[0m\u001b[32m     3.366e+00     |\u001b[0m\u001b[32m     3.366e+00     |\u001b[0m\n",
      "\u001b[32m|  10/10   |\u001b[0m\u001b[32m     2.379e+00     |\u001b[0m\u001b[32m     2.379e+00     |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Training Time =============================\u001b[0m\n",
      "\u001b[32mTotal time of Training:       0.030000686645507812\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_parameters = model.trainModel(models='model', train_dataset='dataset', num_of_epochs=10, lr=0.01, shuffle_data=True, train_batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To automatically splits the dataset between training set and validation set, just provide the datasets to use inside the `dataset` parameter.\n",
    "\n",
    "In this way, the parameter `splits` will be used to splits the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m======================== nnodely Model Train Parameters ========================\u001b[0m\n",
      "\u001b[32mmodels:                       ['model']\u001b[0m\n",
      "\u001b[32mnum of epochs:                10\u001b[0m\n",
      "\u001b[32mupdate per epochs:            4\u001b[0m\n",
      "\u001b[34m└>(n_samples-batch_size)/batch_size+1\u001b[0m\n",
      "\u001b[32mshuffle _data:                True\u001b[0m\n",
      "\u001b[32mtrain dataset:                dataset_train\u001b[0m\n",
      "\u001b[32m\t- num of samples:            19\u001b[0m\n",
      "\u001b[32m\t- batch size:                4\u001b[0m\n",
      "\u001b[32m\t- unused samples:            3\u001b[0m\n",
      "\u001b[34m\t  └>n_samples-update_per_epochs*batch_size\u001b[0m\n",
      "\u001b[32mval dataset:                  None\u001b[0m\n",
      "\u001b[32mval {batch size, samples}:    {5, 5}\u001b[0m\n",
      "\u001b[32mminimizers:                   {'error': {'A': 'Fir2',\n",
      "                                         'B': 'SamplePart4',\n",
      "                                         'loss': 'mse'}}\u001b[0m\n",
      "\u001b[32moptimizer:                    Adam\u001b[0m\n",
      "\u001b[32moptimizer defaults:           {'lr': 0.001}\u001b[0m\n",
      "\u001b[32moptimizer params:             [{'params': 'PFir3W'}]\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================= nnodely Training =================\u001b[0m\n",
      "\u001b[32m|  Epoch   |\u001b[0m\u001b[32m       error       |\u001b[0m\u001b[32m       Total       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m        Loss       |\u001b[0m\u001b[32m        Loss       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m  train  |\u001b[0m\u001b[32m   val   |\u001b[0m\u001b[32m  train  |\u001b[0m\u001b[32m   val   |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|   1/10   |\u001b[0m\u001b[32m 2.31e+00|\u001b[0m\u001b[32m1.529e-01|\u001b[0m\u001b[32m 2.31e+00|\u001b[0m\u001b[32m1.529e-01|\u001b[0m\n",
      "\u001b[32m|   2/10   |\u001b[0m\u001b[32m1.742e+00|\u001b[0m\u001b[32m6.559e-01|\u001b[0m\u001b[32m1.742e+00|\u001b[0m\u001b[32m6.559e-01|\u001b[0m\n",
      "\u001b[32m|   3/10   |\u001b[0m\u001b[32m1.944e+00|\u001b[0m\u001b[32m1.486e+00|\u001b[0m\u001b[32m1.944e+00|\u001b[0m\u001b[32m1.486e+00|\u001b[0m\n",
      "\u001b[32m|   4/10   |\u001b[0m\u001b[32m1.504e+00|\u001b[0m\u001b[32m2.463e+00|\u001b[0m\u001b[32m1.504e+00|\u001b[0m\u001b[32m2.463e+00|\u001b[0m\n",
      "\u001b[32m|   5/10   |\u001b[0m\u001b[32m1.412e+00|\u001b[0m\u001b[32m3.377e+00|\u001b[0m\u001b[32m1.412e+00|\u001b[0m\u001b[32m3.377e+00|\u001b[0m\n",
      "\u001b[32m|   6/10   |\u001b[0m\u001b[32m1.254e+00|\u001b[0m\u001b[32m3.981e+00|\u001b[0m\u001b[32m1.254e+00|\u001b[0m\u001b[32m3.981e+00|\u001b[0m\n",
      "\u001b[32m|   7/10   |\u001b[0m\u001b[32m1.379e+00|\u001b[0m\u001b[32m4.218e+00|\u001b[0m\u001b[32m1.379e+00|\u001b[0m\u001b[32m4.218e+00|\u001b[0m\n",
      "\u001b[32m|   8/10   |\u001b[0m\u001b[32m1.345e+00|\u001b[0m\u001b[32m4.258e+00|\u001b[0m\u001b[32m1.345e+00|\u001b[0m\u001b[32m4.258e+00|\u001b[0m\n",
      "\u001b[32m|   9/10   |\u001b[0m\u001b[32m1.454e+00|\u001b[0m\u001b[32m4.163e+00|\u001b[0m\u001b[32m1.454e+00|\u001b[0m\u001b[32m4.163e+00|\u001b[0m\n",
      "\u001b[32m|  10/10   |\u001b[0m\u001b[32m1.564e+00|\u001b[0m\u001b[32m3.988e+00|\u001b[0m\u001b[32m1.564e+00|\u001b[0m\u001b[32m3.988e+00|\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Training Time =============================\u001b[0m\n",
      "\u001b[32mTotal time of Training:       0.024994611740112305\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_parameters = model.trainModel(models='model', dataset='dataset', splits=[70, 20, 10], num_of_epochs=10, shuffle_data=True, train_batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Training\n",
    "\n",
    "The recurrent training can take place only when there are recurrent variables, closed-loops or connections between inputs.\n",
    "\n",
    "The recurrent train can also be performed on the run by setting the `closed_loop` dictionary for closed connections and/or by setting the `connect` dictionary for direct connections.\n",
    "\n",
    "In case of a recurrent training, the number of prediction horizon window (`prediction_samples`) must be specified. This is used to select for how many steps doing the recurrent loop\n",
    "\n",
    "The `step` is used to decide whether to skip samples at each epoch. this will ensure a faster training time expecially when the prediction horizon is too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[check_names] The name 'target' is already in defined as NeuObj but it is overwritten.\u001b[0m\n",
      "\u001b[33m[check_names] The name 'out' is already in defined as NeuObj but it is overwritten.\u001b[0m\n",
      "\u001b[1;32m================================ nnodely Model =================================\u001b[0m\n",
      "\u001b[32m{'Constants': {},\n",
      " 'Functions': {},\n",
      " 'Info': {'SampleTime': 0.01,\n",
      "          'nnodely_version': '1.5.0',\n",
      "          'ns': [1, 1],\n",
      "          'ntot': 2,\n",
      "          'num_parameters': 1},\n",
      " 'Inputs': {'target': {'dim': 1, 'ns': [0, 1], 'ntot': 1, 'sw': [0, 1]},\n",
      "            'x': {'closedLoop': 'Fir7',\n",
      "                  'dim': 1,\n",
      "                  'local': 1,\n",
      "                  'ns': [1, 0],\n",
      "                  'ntot': 1,\n",
      "                  'sw': [-1, 0]}},\n",
      " 'Minimizers': {'error': {'A': 'SamplePart9', 'B': 'Fir7', 'loss': 'mse'}},\n",
      " 'Models': 'model',\n",
      " 'Outputs': {'out': 'Fir7'},\n",
      " 'Parameters': {'PFir8W': {'dim': 1,\n",
      "                           'sw': 1,\n",
      "                           'values': [[0.8822692632675171]]}},\n",
      " 'Relations': {'Fir7': ['Fir', ['SamplePart6'], 'PFir8W', None, 0],\n",
      "               'SamplePart6': ['SamplePart', ['x'], -1, [-1, 0]],\n",
      "               'SamplePart9': ['SamplePart', ['target'], -1, [0, 1]]}}\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Model Dataset =============================\u001b[0m\n",
      "\u001b[32mDataset Name:                 dataset\u001b[0m\n",
      "\u001b[32mNumber of files:              1\u001b[0m\n",
      "\u001b[32mTotal number of samples:      19\u001b[0m\n",
      "\u001b[32mShape of x:                   (19, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of target:              (19, 1, 1)\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "target = Input('target')\n",
    "x = Input('x')\n",
    "relation = Fir(x.last())\n",
    "relation.closedLoop(x)\n",
    "output = Output('out', relation)\n",
    "\n",
    "test = Modely(visualizer=TextVisualizer(), seed=42)\n",
    "test.addModel('model', output)\n",
    "test.addMinimize('error', target.next(), relation)\n",
    "test.neuralizeModel(0.01)\n",
    "\n",
    "dataset = {'x': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], 'target': [21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40]}\n",
    "test.loadData(name='dataset', source=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m======================== nnodely Model Train Parameters ========================\u001b[0m\n",
      "\u001b[32mmodels:                       ['model']\u001b[0m\n",
      "\u001b[32mnum of epochs:                10\u001b[0m\n",
      "\u001b[32mupdate per epochs:            3\u001b[0m\n",
      "\u001b[34m└>(n_samples-batch_size-prediction_samples+1)/(batch_size+step-1)+1\u001b[0m\n",
      "\u001b[32mshuffle _data:                True\u001b[0m\n",
      "\u001b[32mprediction samples:           2\u001b[0m\n",
      "\u001b[32mstep:                         1\u001b[0m\n",
      "\u001b[32mclosed loop:                  {}\u001b[0m\n",
      "\u001b[32mconnect:                      {}\u001b[0m\n",
      "\u001b[32mtrain dataset:                dataset\u001b[0m\n",
      "\u001b[32m\t- num of samples:            19\u001b[0m\n",
      "\u001b[32m\t- batch size:                4\u001b[0m\n",
      "\u001b[32m\t- unused samples:            5\u001b[0m\n",
      "\u001b[34m\t  └>n_samples-prediction_samples-update_per_epochs*(batch_size+step-1)\u001b[0m\n",
      "\u001b[32mminimizers:                   {'error': {'A': 'SamplePart9',\n",
      "                                         'B': 'Fir7',\n",
      "                                         'loss': 'mse'}}\u001b[0m\n",
      "\u001b[32moptimizer:                    Adam\u001b[0m\n",
      "\u001b[32moptimizer defaults:           {'lr': 0.01}\u001b[0m\n",
      "\u001b[32moptimizer params:             [{'params': 'PFir8W'}]\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================= nnodely Training =================\u001b[0m\n",
      "\u001b[32m|  Epoch   |\u001b[0m\u001b[32m       error       |\u001b[0m\u001b[32m       Total       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m        Loss       |\u001b[0m\u001b[32m        Loss       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m       train       |\u001b[0m\u001b[32m       train       |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|   1/10   |\u001b[0m\u001b[32m     4.213e+02     |\u001b[0m\u001b[32m     4.213e+02     |\u001b[0m\n",
      "\u001b[32m|   2/10   |\u001b[0m\u001b[32m     4.120e+02     |\u001b[0m\u001b[32m     4.120e+02     |\u001b[0m\n",
      "\u001b[32m|   3/10   |\u001b[0m\u001b[32m     3.957e+02     |\u001b[0m\u001b[32m     3.957e+02     |\u001b[0m\n",
      "\u001b[32m|   4/10   |\u001b[0m\u001b[32m     3.765e+02     |\u001b[0m\u001b[32m     3.765e+02     |\u001b[0m\n",
      "\u001b[32m|   5/10   |\u001b[0m\u001b[32m      3.58e+02     |\u001b[0m\u001b[32m      3.58e+02     |\u001b[0m\n",
      "\u001b[32m|   6/10   |\u001b[0m\u001b[32m     3.395e+02     |\u001b[0m\u001b[32m     3.395e+02     |\u001b[0m\n",
      "\u001b[32m|   7/10   |\u001b[0m\u001b[32m     3.259e+02     |\u001b[0m\u001b[32m     3.259e+02     |\u001b[0m\n",
      "\u001b[32m|   8/10   |\u001b[0m\u001b[32m     2.979e+02     |\u001b[0m\u001b[32m     2.979e+02     |\u001b[0m\n",
      "\u001b[32m|   9/10   |\u001b[0m\u001b[32m      2.89e+02     |\u001b[0m\u001b[32m      2.89e+02     |\u001b[0m\n",
      "\u001b[32m|  10/10   |\u001b[0m\u001b[32m     2.871e+02     |\u001b[0m\u001b[32m     2.871e+02     |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Training Time =============================\u001b[0m\n",
      "\u001b[32mTotal time of Training:       0.039998769760131836\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_parameters = test.trainModel(train_dataset='dataset', lr=0.01, num_of_epochs=10, train_batch_size=4, prediction_samples=2, step=1, shuffle_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set different weight for the minimization functions\n",
    "\n",
    "use the `minimize_gain` attribute to modify the importance of certain minimization functions by passing a dictionary with the gain factor for each minimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m======================== nnodely Model Train Parameters ========================\u001b[0m\n",
      "\u001b[32mmodels:                       ['model']\u001b[0m\n",
      "\u001b[32mnum of epochs:                100\u001b[0m\n",
      "\u001b[32mupdate per epochs:            1\u001b[0m\n",
      "\u001b[34m└>(n_samples-batch_size-prediction_samples+1)/(batch_size+step-1)+1\u001b[0m\n",
      "\u001b[32mshuffle _data:                True\u001b[0m\n",
      "\u001b[32mprediction samples:           0\u001b[0m\n",
      "\u001b[32mstep:                         0\u001b[0m\n",
      "\u001b[32mclosed loop:                  {}\u001b[0m\n",
      "\u001b[32mconnect:                      {}\u001b[0m\n",
      "\u001b[32mtrain dataset:                dataset\u001b[0m\n",
      "\u001b[32m\t- num of samples:            19\u001b[0m\n",
      "\u001b[32m\t- batch size:                19\u001b[0m\n",
      "\u001b[32m\t- unused samples:            0\u001b[0m\n",
      "\u001b[34m\t  └>n_samples-prediction_samples-update_per_epochs*(batch_size+step-1)\u001b[0m\n",
      "\u001b[32mminimizers:                   {'error': {'A': 'SamplePart9',\n",
      "                                         'B': 'Fir7',\n",
      "                                         'gain': 0,\n",
      "                                         'loss': 'mse'}}\u001b[0m\n",
      "\u001b[32moptimizer:                    Adam\u001b[0m\n",
      "\u001b[32moptimizer defaults:           {'lr': 0.001}\u001b[0m\n",
      "\u001b[32moptimizer params:             [{'params': 'PFir8W'}]\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================= nnodely Training =================\u001b[0m\n",
      "\u001b[32m|  Epoch   |\u001b[0m\u001b[32m       error       |\u001b[0m\u001b[32m       Total       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m        Loss       |\u001b[0m\u001b[32m        Loss       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m       train       |\u001b[0m\u001b[32m       train       |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|  10/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  20/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  30/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  40/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  50/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  60/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  70/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  80/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  90/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m| 100/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Training Time =============================\u001b[0m\n",
      "\u001b[32mTotal time of Training:       0.08199954032897949\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_parameters = test.trainModel(train_dataset='dataset', minimize_gain={'error':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Optimizer\n",
    "\n",
    "There are various ways to configure the optimizer to use during the training process.\n",
    "\n",
    "This can be achieved by selecting the name of the optimizer to use from the pytorch list and then passing a dictionary of options to configure the desired optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m======================== nnodely Model Train Parameters ========================\u001b[0m\n",
      "\u001b[32mmodels:                       ['model']\u001b[0m\n",
      "\u001b[32mnum of epochs:                10\u001b[0m\n",
      "\u001b[32mupdate per epochs:            1\u001b[0m\n",
      "\u001b[34m└>(n_samples-batch_size-prediction_samples+1)/(batch_size+step-1)+1\u001b[0m\n",
      "\u001b[32mshuffle _data:                True\u001b[0m\n",
      "\u001b[32mprediction samples:           0\u001b[0m\n",
      "\u001b[32mstep:                         0\u001b[0m\n",
      "\u001b[32mclosed loop:                  {}\u001b[0m\n",
      "\u001b[32mconnect:                      {}\u001b[0m\n",
      "\u001b[32mtrain dataset:                dataset\u001b[0m\n",
      "\u001b[32m\t- num of samples:            19\u001b[0m\n",
      "\u001b[32m\t- batch size:                19\u001b[0m\n",
      "\u001b[32m\t- unused samples:            0\u001b[0m\n",
      "\u001b[34m\t  └>n_samples-prediction_samples-update_per_epochs*(batch_size+step-1)\u001b[0m\n",
      "\u001b[32mminimizers:                   {'error': {'A': 'SamplePart9',\n",
      "                                         'B': 'Fir7',\n",
      "                                         'loss': 'mse'}}\u001b[0m\n",
      "\u001b[32moptimizer:                    Adam\u001b[0m\n",
      "\u001b[32moptimizer defaults:           {'betas': (0.5, 0.99), 'lr': 0.1}\u001b[0m\n",
      "\u001b[32moptimizer params:             [{'params': 'PFir8W'}]\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================= nnodely Training =================\u001b[0m\n",
      "\u001b[32m|  Epoch   |\u001b[0m\u001b[32m       error       |\u001b[0m\u001b[32m       Total       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m        Loss       |\u001b[0m\u001b[32m        Loss       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m       train       |\u001b[0m\u001b[32m       train       |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|   1/10   |\u001b[0m\u001b[32m     3.712e+02     |\u001b[0m\u001b[32m     3.712e+02     |\u001b[0m\n",
      "\u001b[32m|   2/10   |\u001b[0m\u001b[32m     3.350e+02     |\u001b[0m\u001b[32m     3.350e+02     |\u001b[0m\n",
      "\u001b[32m|   3/10   |\u001b[0m\u001b[32m     3.019e+02     |\u001b[0m\u001b[32m     3.019e+02     |\u001b[0m\n",
      "\u001b[32m|   4/10   |\u001b[0m\u001b[32m     2.719e+02     |\u001b[0m\u001b[32m     2.719e+02     |\u001b[0m\n",
      "\u001b[32m|   5/10   |\u001b[0m\u001b[32m     2.451e+02     |\u001b[0m\u001b[32m     2.451e+02     |\u001b[0m\n",
      "\u001b[32m|   6/10   |\u001b[0m\u001b[32m     2.215e+02     |\u001b[0m\u001b[32m     2.215e+02     |\u001b[0m\n",
      "\u001b[32m|   7/10   |\u001b[0m\u001b[32m     2.008e+02     |\u001b[0m\u001b[32m     2.008e+02     |\u001b[0m\n",
      "\u001b[32m|   8/10   |\u001b[0m\u001b[32m     1.830e+02     |\u001b[0m\u001b[32m     1.830e+02     |\u001b[0m\n",
      "\u001b[32m|   9/10   |\u001b[0m\u001b[32m     1.678e+02     |\u001b[0m\u001b[32m     1.678e+02     |\u001b[0m\n",
      "\u001b[32m|  10/10   |\u001b[0m\u001b[32m     1.549e+02     |\u001b[0m\u001b[32m     1.549e+02     |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Training Time =============================\u001b[0m\n",
      "\u001b[32mTotal time of Training:       0.009000539779663086\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "optimizer_defaults = {\n",
    "            'lr': 0.1,\n",
    "            'betas': (0.5, 0.99)\n",
    "        }\n",
    "\n",
    "training_parameters = test.trainModel(train_dataset='dataset', optimizer='Adam', optimizer_defaults=optimizer_defaults, num_of_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping and Best Model\n",
    "\n",
    "Use one of the built-in early stopping and selection model functions or use a custom one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m======================== nnodely Model Train Parameters ========================\u001b[0m\n",
      "\u001b[32mmodels:                       ['model']\u001b[0m\n",
      "\u001b[32mnum of epochs:                100\u001b[0m\n",
      "\u001b[32mupdate per epochs:            1\u001b[0m\n",
      "\u001b[34m└>(n_samples-batch_size-prediction_samples+1)/(batch_size+step-1)+1\u001b[0m\n",
      "\u001b[32mshuffle _data:                True\u001b[0m\n",
      "\u001b[32mearly stopping:               early_stop_patience\u001b[0m\n",
      "\u001b[32mearly stopping params:        {}\u001b[0m\n",
      "\u001b[32mprediction samples:           0\u001b[0m\n",
      "\u001b[32mstep:                         0\u001b[0m\n",
      "\u001b[32mclosed loop:                  {}\u001b[0m\n",
      "\u001b[32mconnect:                      {}\u001b[0m\n",
      "\u001b[32mtrain dataset:                dataset\u001b[0m\n",
      "\u001b[32m\t- num of samples:            19\u001b[0m\n",
      "\u001b[32m\t- batch size:                19\u001b[0m\n",
      "\u001b[32m\t- unused samples:            0\u001b[0m\n",
      "\u001b[34m\t  └>n_samples-prediction_samples-update_per_epochs*(batch_size+step-1)\u001b[0m\n",
      "\u001b[32mminimizers:                   {'error': {'A': 'SamplePart9',\n",
      "                                         'B': 'Fir7',\n",
      "                                         'gain': 0,\n",
      "                                         'loss': 'mse'}}\u001b[0m\n",
      "\u001b[32moptimizer:                    Adam\u001b[0m\n",
      "\u001b[32moptimizer defaults:           {'lr': 0.001}\u001b[0m\n",
      "\u001b[32moptimizer params:             [{'params': 'PFir8W'}]\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================= nnodely Training =================\u001b[0m\n",
      "\u001b[32m|  Epoch   |\u001b[0m\u001b[32m       error       |\u001b[0m\u001b[32m       Total       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m        Loss       |\u001b[0m\u001b[32m        Loss       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m       train       |\u001b[0m\u001b[32m       train       |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|  10/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  20/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  30/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "|  32/100  |       0.e+00      |       0.e+00      |"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m|  40/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[32m|  50/100  |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\u001b[32m       0.e+00      |\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Training Time =============================\u001b[0m\n",
      "\u001b[32mTotal time of Training:       0.07100605964660645\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from nnodely.support.earlystopping import early_stop_patience, select_best_model\n",
    "training_parameters = test.trainModel(train_dataset='dataset', minimize_gain={'error':0}, early_stopping=early_stop_patience, select_model=select_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Analyze\n",
    "\n",
    "the function `trainAndAnalyze` is a convenient way to do the training and validation at the same time. \n",
    "\n",
    "With the following function the user can use a test dataset to assess the quality of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m============================ nnodely Model Dataset =============================\u001b[0m\n",
      "\u001b[32mDataset Name:                 dataset_test\u001b[0m\n",
      "\u001b[32mNumber of files:              1\u001b[0m\n",
      "\u001b[32mTotal number of samples:      27\u001b[0m\n",
      "\u001b[32mShape of in1:                 (27, 5, 1)\u001b[0m\n",
      "\u001b[32mShape of target:              (27, 1, 1)\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Model Dataset =============================\u001b[0m\n",
      "\u001b[32mDataset Name:                 dataset_val\u001b[0m\n",
      "\u001b[32mNumber of files:              1\u001b[0m\n",
      "\u001b[32mTotal number of samples:      27\u001b[0m\n",
      "\u001b[32mShape of in1:                 (27, 5, 1)\u001b[0m\n",
      "\u001b[32mShape of target:              (27, 1, 1)\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m======================== nnodely Model Train Parameters ========================\u001b[0m\n",
      "\u001b[32mmodels:                       ['model']\u001b[0m\n",
      "\u001b[32mnum of epochs:                10\u001b[0m\n",
      "\u001b[32mupdate per epochs:            6\u001b[0m\n",
      "\u001b[34m└>(n_samples-batch_size)/batch_size+1\u001b[0m\n",
      "\u001b[32mshuffle _data:                True\u001b[0m\n",
      "\u001b[32mtrain dataset:                dataset\u001b[0m\n",
      "\u001b[32m\t- num of samples:            27\u001b[0m\n",
      "\u001b[32m\t- batch size:                4\u001b[0m\n",
      "\u001b[32m\t- unused samples:            3\u001b[0m\n",
      "\u001b[34m\t  └>n_samples-update_per_epochs*batch_size\u001b[0m\n",
      "\u001b[32mval dataset:                  dataset_val\u001b[0m\n",
      "\u001b[32mval {batch size, samples}:    {27, 27}\u001b[0m\n",
      "\u001b[32mminimizers:                   {'error': {'A': 'Fir2',\n",
      "                                         'B': 'SamplePart4',\n",
      "                                         'loss': 'mse'}}\u001b[0m\n",
      "\u001b[32moptimizer:                    Adam\u001b[0m\n",
      "\u001b[32moptimizer defaults:           {'lr': 0.01}\u001b[0m\n",
      "\u001b[32moptimizer params:             [{'params': 'PFir3W'}]\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================= nnodely Training =================\u001b[0m\n",
      "\u001b[32m|  Epoch   |\u001b[0m\u001b[32m       error       |\u001b[0m\u001b[32m       Total       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m        Loss       |\u001b[0m\u001b[32m        Loss       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m  train  |\u001b[0m\u001b[32m   val   |\u001b[0m\u001b[32m  train  |\u001b[0m\u001b[32m   val   |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|   1/10   |\u001b[0m\u001b[32m1.929e+00|\u001b[0m\u001b[32m1.635e+00|\u001b[0m\u001b[32m1.929e+00|\u001b[0m\u001b[32m1.635e+00|\u001b[0m\n",
      "\u001b[32m|   2/10   |\u001b[0m\u001b[32m1.961e+00|\u001b[0m\u001b[32m1.623e+00|\u001b[0m\u001b[32m1.961e+00|\u001b[0m\u001b[32m1.623e+00|\u001b[0m\n",
      "\u001b[32m|   3/10   |\u001b[0m\u001b[32m1.617e+00|\u001b[0m\u001b[32m1.776e+00|\u001b[0m\u001b[32m1.617e+00|\u001b[0m\u001b[32m1.776e+00|\u001b[0m\n",
      "\u001b[32m|   4/10   |\u001b[0m\u001b[32m1.671e+00|\u001b[0m\u001b[32m1.432e+00|\u001b[0m\u001b[32m1.671e+00|\u001b[0m\u001b[32m1.432e+00|\u001b[0m\n",
      "\u001b[32m|   5/10   |\u001b[0m\u001b[32m1.603e+00|\u001b[0m\u001b[32m 1.41e+00|\u001b[0m\u001b[32m1.603e+00|\u001b[0m\u001b[32m 1.41e+00|\u001b[0m\n",
      "\u001b[32m|   6/10   |\u001b[0m\u001b[32m1.623e+00|\u001b[0m\u001b[32m1.408e+00|\u001b[0m\u001b[32m1.623e+00|\u001b[0m\u001b[32m1.408e+00|\u001b[0m\n",
      "\u001b[32m|   7/10   |\u001b[0m\u001b[32m1.455e+00|\u001b[0m\u001b[32m1.406e+00|\u001b[0m\u001b[32m1.455e+00|\u001b[0m\u001b[32m1.406e+00|\u001b[0m\n",
      "\u001b[32m|   8/10   |\u001b[0m\u001b[32m1.403e+00|\u001b[0m\u001b[32m1.358e+00|\u001b[0m\u001b[32m1.403e+00|\u001b[0m\u001b[32m1.358e+00|\u001b[0m\n",
      "\u001b[32m|   9/10   |\u001b[0m\u001b[32m1.495e+00|\u001b[0m\u001b[32m1.288e+00|\u001b[0m\u001b[32m1.495e+00|\u001b[0m\u001b[32m1.288e+00|\u001b[0m\n",
      "\u001b[32m|  10/10   |\u001b[0m\u001b[32m1.386e+00|\u001b[0m\u001b[32m1.249e+00|\u001b[0m\u001b[32m1.386e+00|\u001b[0m\u001b[32m1.249e+00|\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[1;32m============================ nnodely Training Time =============================\u001b[0m\n",
      "\u001b[32mTotal time of Training:       0.036997079849243164\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================ nnodely Model Results for dataset ================\u001b[0m\n",
      "\u001b[32m| Loss|\u001b[0m\u001b[32m        mse        |\u001b[0m\u001b[32m        FVU        |\u001b[0m\u001b[32m        AIC        |\u001b[0m\n",
      "\u001b[32m|     |\u001b[0m\u001b[32m    small better   |\u001b[0m\u001b[32m    small better   |\u001b[0m\u001b[32m    lower better   |\u001b[0m\n",
      "\u001b[32m|-----------------------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|error|\u001b[0m\u001b[32m      1.27e+00     |\u001b[0m\u001b[32m     1.464e-02     |\u001b[0m\u001b[32m     8.712e+01     |\u001b[0m\n",
      "\u001b[32m|-----------------------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|Total|\u001b[0m\u001b[32m      1.27e+00     |\u001b[0m\u001b[32m     1.464e-02     |\u001b[0m\u001b[32m     8.712e+01     |\u001b[0m\n",
      "\u001b[32m|-----------------------------------------------------------------|\u001b[0m\n",
      "\u001b[1;32m============== nnodely Model Results for dataset_val ==============\u001b[0m\n",
      "\u001b[32m| Loss|\u001b[0m\u001b[32m        mse        |\u001b[0m\u001b[32m        FVU        |\u001b[0m\u001b[32m        AIC        |\u001b[0m\n",
      "\u001b[32m|     |\u001b[0m\u001b[32m    small better   |\u001b[0m\u001b[32m    small better   |\u001b[0m\u001b[32m    lower better   |\u001b[0m\n",
      "\u001b[32m|-----------------------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|error|\u001b[0m\u001b[32m     1.249e+00     |\u001b[0m\u001b[32m     1.464e-02     |\u001b[0m\u001b[32m     9.337e+01     |\u001b[0m\n",
      "\u001b[32m|-----------------------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|Total|\u001b[0m\u001b[32m     1.249e+00     |\u001b[0m\u001b[32m     1.464e-02     |\u001b[0m\u001b[32m     9.337e+01     |\u001b[0m\n",
      "\u001b[32m|-----------------------------------------------------------------|\u001b[0m\n",
      "\u001b[1;32m============== nnodely Model Results for dataset_test =============\u001b[0m\n",
      "\u001b[32m| Loss|\u001b[0m\u001b[32m        mse        |\u001b[0m\u001b[32m        FVU        |\u001b[0m\u001b[32m        AIC        |\u001b[0m\n",
      "\u001b[32m|     |\u001b[0m\u001b[32m    small better   |\u001b[0m\u001b[32m    small better   |\u001b[0m\u001b[32m    lower better   |\u001b[0m\n",
      "\u001b[32m|-----------------------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|error|\u001b[0m\u001b[32m     1.249e+00     |\u001b[0m\u001b[32m     1.464e-02     |\u001b[0m\u001b[32m     9.337e+01     |\u001b[0m\n",
      "\u001b[32m|-----------------------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|Total|\u001b[0m\u001b[32m     1.249e+00     |\u001b[0m\u001b[32m     1.464e-02     |\u001b[0m\u001b[32m     9.337e+01     |\u001b[0m\n",
      "\u001b[32m|-----------------------------------------------------------------|\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_folder = 'data'\n",
    "data_struct = ['in1', '', 'target']\n",
    "model.loadData(name='dataset_test', source=test_folder, format=data_struct, skiplines=1)\n",
    "model.loadData(name='dataset_val', source=test_folder, format=data_struct, skiplines=1)\n",
    "\n",
    "training_parameters = model.trainAndAnalyze(models='model', train_dataset='dataset', validation_dataset='dataset_val', train_batch_size=4, test_dataset='dataset_test', test_batch_size=1, num_of_epochs=10, lr=0.01, shuffle_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'add_optimizer_defaults': {},\n",
      " 'add_optimizer_params': [],\n",
      " 'all_models': ['model'],\n",
      " 'closed_loop': {},\n",
      " 'connect': {},\n",
      " 'dataset': None,\n",
      " 'early_stopping': None,\n",
      " 'early_stopping_params': {},\n",
      " 'minimize_gain': {},\n",
      " 'minimizers': {'error': {'A': 'Fir2', 'B': 'SamplePart4', 'loss': 'mse'}},\n",
      " 'models': ['model'],\n",
      " 'n_samples_test': 27,\n",
      " 'n_samples_train': 27,\n",
      " 'n_samples_val': 27,\n",
      " 'name': None,\n",
      " 'num_of_epochs': 10,\n",
      " 'optimizer': 'Adam',\n",
      " 'optimizer_defaults': {'lr': 0.01},\n",
      " 'optimizer_params': [{'params': 'PFir3W'}],\n",
      " 'prediction_samples': -1,\n",
      " 'select_model': 'last',\n",
      " 'select_model_params': {},\n",
      " 'shuffle_data': True,\n",
      " 'splits': [100, 0, 0],\n",
      " 'step': 0,\n",
      " 'test_batch_size': 1,\n",
      " 'test_step': 0,\n",
      " 'test_tag': 'dataset_test',\n",
      " 'train_batch_size': 4,\n",
      " 'train_dataset': 'dataset',\n",
      " 'train_step': 0,\n",
      " 'train_tag': 'dataset',\n",
      " 'unused_samples': 3,\n",
      " 'update_per_epochs': 6,\n",
      " 'val_batch_size': 27,\n",
      " 'val_step': 0,\n",
      " 'val_tag': 'dataset_val',\n",
      " 'validation_dataset': 'dataset_val'}\n",
      "Training completed with parameters: None\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print(\"Training completed with parameters:\", pprint.pprint(training_parameters))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
